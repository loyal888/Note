# 一、音频的表示

---

根据编码方式的不同，音频编码技术分为三种：**波形编码、参数编码和混合编码**。一般来说，波形编码的话音质量高，但码率也很高；参数编码的码率很低，产生的合成语音的音质不高；混合编码使用参数编码技术和波形编码技术，编码率和音质介于它们之间。

> **波形编码**：当模拟信号由于传输损失而变弱时，很难将复杂的模拟结构从随机的传输噪音结构中分离出来。如果放大模拟信号，噪音也会放大，最终会导致模拟连接由于过于嘈杂而无法使用。只具有“一位”和“零位”状态的**数字信号**则更容易从噪音中分离出来。它们可以被无损放大。在长距离连接中，数字编码更不容易受到噪音损失的影响。**波形编码就是根据语音信号波形导出相应的数字编码形式，使其在接收端能忠实再现原始语音。**

> **参数编码**：通过对语音信号特征参数的提取及编码，力求使重建语音讯号具有尽可能高的清晰度，即保持原语音的语义，而重建讯号的波形可能同原始语音讯号有较大的差别。

最简单的波形编码方法是 **PCM（Pulse Code Modulation，脉冲编码调制）**，它只对语音信号进行采样和量化处理。优点是编码方法简单，延迟时间短，音质高，重构的语音信号与原始语音信号几乎没有差别。

---

## What is PCM?

PCM(Pulse-code-modulation)是模拟信号以固定的采样频率转换成数字信号后的表现形式。

主要参数有采样率（Sample Rate ）、符号（Sign）、采样数据大小（Sample Size）、字节序（Byte Ordering）、声道（Number of Channels）。

#### 如何使用pcm？可以使用ffmplay播放pcm文件。

```
ffplay -ar 44100 -ac 2 -f s16le -i hurt.pcm
```

### pcm转换为常用的音频格式（eg:mp3、flac、wav)？

pcm文件文件是无损格式，缺点是占用的存储空间较大。

<div>
       要算一个 PCM 音频流的码率是一件很轻松的事情，采样率值 × 采样大小值 × 声道数 bps。一个采样率为 44.1KHz，采样大小为 16bit，双声道的 PCM 编码的 WAV 文件，它的数据速率则为 44.1K×16×2 =1411.2 Kbps。我们常说 128K 的 MP3，对应的 WAV 的参数，就是这个 1411.2 Kbps，这个参数也被称为数据带宽，它和 ADSL 中的带宽是一个概念。将码率除以 8, 就可以得到这个 WAV 的数据速率，即 176.4KB/s。这表示存储一秒钟采样率为 44.1KHz，采样大小为 16bit，双声道的 PCM 编码的音频信号，需要 176.4KB 的空间，1 分钟则约为 10.34M，这对大部分用户是不可接受的。
</div>

**数据有损压缩**是必然。MP3由德国 Fraunhofer IIS 研究院和汤姆生公司1993 年合作发展成功。MP3 可以做到 **12:1**的惊人压缩比并保持基本可听的音质。为什么能做到12:1？

> 专家们通过长期的声学研究，发现人耳存在遮蔽效应。声音信号实际是一种能量波，在空气或其他媒介中传播，人耳对声音能量的多少即响度或声压最直接的反应就是听到这个声音的大小，我们称它为响度，表示响度这种能量的单位为分贝（dB）。即使是同样响度的声音，人们也会因为它们频率不同而感觉到声音大小不同。人耳最容易听到的就是 500Hz 的频率，不管频率是否增高或降低，即使是响度在相同的情况下，大家都会觉得声音在变小。但响度降到一定程度时，人耳就听不到了，每一个频率都有着不同的值。
> 
> ![https//timgsabaiducom/timg?image&quality=80&size=b999910000&sec=1598871667268&di=2864168520794a9ce364f673f6f0bd6d&imgtype=0&src=http%3A%2F%2Fww2sinaimgcn%2Flarge%2F67353d05jw1en3xo3f03rg20br0910t8gif](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1598871667268&di=2864168520794a9ce364f673f6f0bd6d&imgtype=0&src=http%3A%2F%2Fww2.sinaimg.cn%2Flarge%2F67353d05jw1en3xo3f03rg20br0910t8.gif)
> 
> **等响曲线**
> 
> 可以看到这条曲线基本成一个 V 字型，当频率超过 15000Hz 时，人耳的会感觉到声音很小，很多听觉不是很好的人，根本就听不到 20000Hz 的频率，不管响度有多大。当人耳同时听到两个不同频率、不同响度的声音时，响度较小的那个也会被忽略，例如：在白天我们很难听到电脑中散热风扇的声音，晚上却成了噪声源，根据这种原理，编码器可以过滤掉很多听不到的声音，以简化信息复杂度，增加压缩比，而不明显的降低音质。这种遮蔽被称为同时遮蔽效应。但声音 A 被声音 B 遮蔽，如果 A 处于 B 为中心的遮蔽范围内，遮蔽会更明显, 这个范围叫临界带宽。每一种频率的临界带宽都不一样，频率越高的临界带宽越宽。
> 
> 频率 (Hz) 临界带宽 (Hz) 频率 (Hz) 临界带宽 (Hz)
> 
> 根据这种效应，专家们设计出人耳听觉心理模型，这个模型被导入到 mp3 编码中后，导致了一场翻天覆地的音质革命。

### PCM格式到MP3的转换过程

使用**lame**库。可以将pcm文件转化为压缩mp3文件。

> **About Lame**
> 
> LAME是目前最好的MP3编码引擎。LAME编码出来的MP3音色纯厚、空间宽广、低音清晰、细节表现良好，它独创的心理音响模型技术保证了CD音频还原的真实性，配合[VBR](https://baike.baidu.com/item/VBR/1022738)和ABR参数，音质几乎可以媲美CD音频，但文件体积却非常小。对于一个免费引擎，LAME的优势不言而喻。
> 
> **Lame 可以和ffmpeg结合！**

### **use lame in android?**

Demo地址:[https://github.com/loyal888/Mp3Encoder](https://github.com/loyal888/Mp3Encoder)

> 1. lame的引入
> 
> 2. CMakeLists的配置
> 
> 3. 编码
>    
>    ```kotlin
>    /**  * pcm文件转化为mp3文件  */    fun  pcmFileToMp3(){        // 在高版本需要动态权限配置和在AndroidManifest配置才能使用绝对路径访问到文件        val pcmPath = "/sdcard/hurt.pcm" // 将assets文件夹下复制到/sdcard下        val audioChannels = 2        val sampleRate = 44100        val bitRate = 128 * 1024        val mp3Path = "/sdcard/test.mp3"        init(pcmPath, audioChannels, bitRate, sampleRate, mp3Path)        encode()        destroy()    }
>    ```
>    
>    ```C++
>    // 初始化int Mp3_Encoder::Init(const char *pcmFilePath, const char *mp3FilePath, int sampleRate, int channels, int bitRate) {    int ret = -1; // 返回结果    // 打开pcm文件  'rb'读取二进制文件    pcmFile = fopen(pcmFilePath,"rb");    if(pcmFile){        mp3File =  fopen(mp3FilePath,"wb");        if(mp3File){            lameClient = lame_init();            // 设置参数            lame_set_in_samplerate(lameClient,sampleRate);            lame_set_out_samplerate(lameClient,sampleRate);            lame_set_num_channels(lameClient,channels);            lame_set_brate(lameClient,bitRate/1000);            lame_init_params(lameClient);            return 0;        }    }    return ret;}// 编码void Mp3_Encoder::Encode() {    int bufferSize = 1024 * 256;//256k;    short* buffer = new short [bufferSize/2];    short * leftBuffer = new short[bufferSize/4];    short * rightBuffer = new short[bufferSize/4];    unsigned char* mp3_buffer = new unsigned char [bufferSize];    size_t readBufferSize = 0;// size_t:一个与机器相关的unsigned类型，其大小足以保证存储内存中对象的大小    while ((readBufferSize=fread(buffer,2,bufferSize/2,pcmFile))>0){        for(int i = 0; i < readBufferSize;i++){            if(i%2 == 0){                leftBuffer[i/2] = buffer[i];            }else{                rightBuffer[i/2] =buffer[i];            }        }        size_t wroteSize = lame_encode_buffer(lameClient,(short int *)rightBuffer,(short int *)leftBuffer,(int)(readBufferSize/2),mp3_buffer,bufferSize);        fwrite(mp3_buffer,1,wroteSize,mp3File);    }    delete [] buffer;    delete [] leftBuffer;    delete [] rightBuffer;    delete [] mp3_buffer;}
>    ```

回过头来，pcm文件怎么得到，换句话说**音频如何采集**？

> Android SDK提供了两套音频采集API：**MediaRecorder**和**AudioRecord**。前者对应Java层，可以对麦克风音频数据进行编码压缩（eg：mp3），后者则是底层C++层面，可以让开发者获得**内存中的PCM音频数据**。
> 
> 这里提供一个Demo：[https://github.com/zhanxiaokai/Android-AudioRecorder](https://github.com/zhanxiaokai/Android-AudioRecorder)
> 
> 有兴趣的可以研究下。

---

# 二、视频的表示

###### 图像的表示形式？

![](https://glumes2blog.oss-cn-shenzhen.aliyuncs.com/blog/rgba-pixel.webp)

我们知道任何的图像都可用由**RGBA**组成，例如Android平台使用**RGBA_8888**描述的分辨率1920 * 1080的一张图片，需要占用的内存大小为：**1920 * 1080 * 4 / 1024 / 1024 = 7.91MB**.图像裸数据不利于网络传输，所以需要用到压缩编码，例如**JPEG**压缩。这里图片的压缩就不再展开。

**视频裸数据的表示形式？**

 ![](https://glumes2blog.oss-cn-shenzhen.aliyuncs.com/blog/yuv-pixel.webp)  **YUV**颜色编码采用的是用 **明亮度** 和 **色度** 来指定像素的颜色。

> Y : 明亮度（Luminance、Luma）
> 
> U 和 V:表示色度（Chrominance、Chroma）

那么YUV是如何做到比RGB更节省空间的？

**YUV的采样格式及存储格式**

YUV 图像的主流采样方式有如下三种：

1. YUV 4:4:4 采样
   
   YUV 4:4:4 采样，意味着 Y、U、V 三个分量的采样比例相同，因此在生成的图像里，每个像素的三个分量信息完整，都是 8 bit，也就是一个字节。
   
   ![](https://glumes2blog.oss-cn-shenzhen.aliyuncs.com/blog/yuv-444-format.webp)
   
   <div>
   <p style="color:red;">Y 分量用叉表示，UV 分量用圆圈表示</p>
   </div>
   
   > 假如图像像素为：[Y0 U0 V0]、[Y1 U1 V1]、[Y2 U2 V2]、[Y3 U3 V3]
   > 那么采样的码流为：Y0 U0 V0 Y1 U1 V1 Y2 U2 V2 Y3 U3 V3 
   > 最后映射出的像素点依旧为 [Y0 U0 V0]、[Y1 U1 V1]、[Y2 U2 V2]、[Y3 U3 V3]
   
   可以看到这种采样方式的图像和 RGB 颜色模型的图像大小是一样，并没有达到节省带宽的目的，当将 RGB 图像转换为 YUV 图像时，也是先转换为 YUV 4:4:4 采样的图像。

2. YUV 4:2:2 采样
   
   YUV 4:2:2 采样，意味着 UV 分量是 Y 分量采样的一半，Y 分量和 UV 分量按照 2 : 1 的比例采样。如果水平方向有 10 个像素点，那么采样了 10 个 Y 分量，而只采样了 5 个 UV 分量。
   
   ![](https://glumes2blog.oss-cn-shenzhen.aliyuncs.com/blog/yuv-422-format.webp)
   
   > 假如图像像素为：[Y0 U0 V0]、[Y1 U1 V1]、[Y2 U2 V2]、[Y3 U3 V3]
   >  那么采样的码流为：Y0 U0 Y1 V1 Y2 U2 Y3 V3 
   > 其中，每采样过一个像素点，都会采样其 Y 分量，而 U、V 分量就会间隔一个采集一个。
   > 最后映射出的像素点为 [Y0 U0 V1]、[Y1 U0 V1]、[Y2 U2 V3]、[Y3 U2 V3]
   
   采样的码流映射为像素点，还是要满足每个像素点有 Y、U、V 三个分量。但是可以看到，第一和第二像素点公用了 U0、V1 分量，第三和第四个像素点公用了 U2、V3 分量，这样就节省了图像空间。
   
   一张 1280 * 720 大小的图片，在 YUV 4:2:2 采样时的大小为：
   
   > (1280 * 720 * 8 + 1280 * 720 * 0.5 * 8 * 2）/ 8 / 1024 / 1024 = 1.76 MB

3. YUV 4:2:0 采样
   
   YUV 4:2:0 采样，并不是指只采样 U 分量而不采样 V 分量。而是指，在每一行扫描时，只扫描一种色度分量（U 或者 V），和 Y 分量按照 2 : 1 的方式采样。比如，第一行扫描时，YU 按照 2 : 1 的方式采样，那么第二行扫描时，YV 分量按照 2:1 的方式采样。对于每个色度分量来说，它的水平方向和竖直方向的采样和 Y 分量相比都是 2:1 。
   
   ![](https://glumes2blog.oss-cn-shenzhen.aliyuncs.com/blog/yuv-420-format.jpeg)
   
   > 假设第一行扫描了 U 分量，第二行扫描了 V 分量，那么需要扫描两行才能够组成完整的 UV 分量.
   > 
   > 假设图像像素为：
   > 
   > [Y0 U0 V0]、[Y1 U1 V1]、 [Y2 U2 V2]、 [Y3 U3 V3]
   > [Y5 U5 V5]、[Y6 U6 V6]、 [Y7 U7 V7] 、[Y8 U8 V8]
   > 
   > 那么采样的码流为：Y0 U0 Y1 Y2 U2 Y3 Y5 V5 Y6 Y7 V7 Y8
   > 
   > 其中，每采样过一个像素点，都会采样其 Y 分量，而 U、V 分量就会间隔一行按照 2 : 1 进行采样。
   > 
   > 最后映射出的像素点为：
   > [Y0 U0 V5]、[Y1 U0 V5]、[Y2 U2 V7]、[Y3 U2 V7]
   > [Y5 U0 V5]、[Y6 U0 V5]、[Y7 U2 V7]、[Y8 U2 V7]
   
   从映射出的像素点中可以看到，四个 Y 分量是共用了一套 UV 分量，而且是按照 2*2 的小方格的形式分布的，相比 YUV 4:2:2 采样中两个 Y 分量共用一套 UV 分量，这样更能够节省空间。
   
   一张 1280 * 720 大小的图片，在 YUV 4:2:0 采样时的大小为：
   
   > （1280 * 720 * 8 + 1280 * 720 * 0.25 * 8 * 2）/ 8 / 1024 / 1024 = 1.32 MB

        可以看到 YUV 4:2:0 采样的图像比 RGB 模型图像节省了一半的存储空间，因此它也是比较主流的采样方式。

**YUV存储**

YUV 的存储格式，有两种：

- planar 平面格式
  - 指先连续存储所有像素点的 Y 分量，然后存储 U 分量，最后是 V 分量。
- packed 打包模式
  - 指每个像素点的 Y、U、V 分量是连续交替存储的。

时间有限，以    **YUV420P**举例：

![](https://glumes2blog.oss-cn-shenzhen.aliyuncs.com/blog/yuv-420p.png)

从信息论的观点来看，描述信源的数据是信息和数据冗余之和，即：**数据 = 信息 + 数据冗余**

**那么视频编码如何去除数据冗余？**

> 帧间编码：去除时间上的冗余信息（eg：运动补偿、运动表示、运动估计），**B、P帧**。
> 
> 帧内编码：去除空间上的冗余，**I帧**就属于帧内编码。
> 
> ![](https://img-blog.csdn.net/20170215094514142?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2w4MDIzZHhm/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)
> **什么是IPB帧？**
> 
> **I帧**：I帧又称帧内编码帧，是一种自带全部信息的独立帧，无需参考其他图像便可独立进行解码，可以简单理解为一张静态画面。视频序列中的第一个帧始终都是I帧，因为它是关键帧。
> 
> ![](https://upload-images.jianshu.io/upload_images/3733860-47eb87dbe7f9c121.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/640/format/webp)
> 
> P帧：P帧又称帧间预测编码帧，**需要参考前面的I帧才能进行编码**。**表示的是当前帧画面与前一帧（前一帧可能是I帧也可能是P帧）的差别**。解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面。与I帧相比，P帧通常占用更少的数据位，但不足是，由于P帧对前面的P和I参考帧有着复杂的依耐性，因此对传输错误非常敏感。
> 
> ![](https://upload-images.jianshu.io/upload_images/3733860-ee93d9a3bd49eaf8.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/557/format/webp)
> 
> **B帧**：B帧又称双向预测编码帧，也就是**B帧记录的是本帧与前后帧的差别**。也就是说要解码B帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的与本帧数据的叠加取得最终的画面。B帧压缩率高，但是对解码性能要求较高。
> 
> ![](https://upload-images.jianshu.io/upload_images/3733860-5d0e502d0f9548a7.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/640/format/webp)

# 三、视频的编码

> ![20200901103031image.png](https://wos.58cdn.com.cn/IjGfEdCbIlr/ishare/4256ed36-5c26-430c-91f7-8312383e2cb52020-09-01-10-30-31-image.png)

> ![](https://wos.58cdn.com.cn/IjGfEdCbIlr/ishare/e6a674d6-af9f-4b4a-9a9f-4b6e1f70a7b42020-09-01-10-31-37-image.png)![](/Users/loyal888/Library/Application Support/marktext/images/2020-09-01-10-31-37-image.png)
